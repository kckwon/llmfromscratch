# Chapter 3

- Q. Self Attention 추가 학습하기

[Attention Is All You Need 논문 중 Self Attention 리뷰](https://ffighting.net/deep-learning-paper-review/language-model/transformer/)
[Self Attention 설명 : 최소한의 수식과 관련 논문으로 쉽게 이해하기](https://ffighting.net/deep-learning-basic/%EB%94%A5%EB%9F%AC%EB%8B%9D-%ED%95%B5%EC%8B%AC-%EA%B0%9C%EB%85%90/attention-and-self-attention-in-deep-learning/)
